# CSSEM condtional on theta
cssemKolen <- matrix(NA,nrow = numOfQuad, ncol = 1)
for (i in 1:numOfQuad){
# cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:41),42] - fxThetaTSS[42, i])^2 * fxThetaTSS[c(1:41),i]))
cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:(numOfItem+1)),(numOfQuad+1)] - fxThetaTSS[(numOfItem+2), i])^2 * fxThetaTSS[c(1:(numOfItem+1)),i]))
}
# error variance: avarage CSSEM across theta distribution
errorVarKolen <- sum(cssemKolen^2 * quadPoints$weights)
# read conversion tables
convTable_A <- read.csv("TestData/ConversionTableFormX.csv")
convTable_A$roundedSS <- round(convTable_A$unroundedSS)
convTable_B <- read.csv("TestData/ConversionTableFormY.csv")
convTable_B$roundedSS <- round(convTable_B$unroundedSS)
KolenRelIRT_A <- KolenRelIRT(itemPara_A, convTable_A)
KolenRelIRT_A
KolenRelIRT_B <- KolenRelIRT(itemPara_B, convTable_B)
KolenRelIRT_B
itemPara <- itemPara_A
convTable <- convTable_A
if (ncol(itemPara) == 3){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a", "c")
}
if (ncol(itemPara) == 2){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara$c <- 0
}
if (ncol(itemPara) == 1){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b")
itemPara$a <- 1
itemPara$c <- 0
}
# number of quadrature
numOfQuad <- 41
# number of Items
numOfItem <- nrow(itemPara)
# weights and nodes
quadPoints <- NormalQuadraPoints(numOfQuad)
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(numOfItem), each = numOfQuad),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = numOfQuad*numOfItem)
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = c + (1 - c) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# reorder matrix by theta
itemParaRep <- itemParaRep[order(itemParaRep$theta),]
# create matrix to store f(x|theta)
fxTheta <- matrix(NA, nrow = numOfQuad, ncol = numOfItem + 1)
# for loop to calculate fxTheta
for (i in 1:numOfQuad){
probs <- matrix(c(itemParaRep[(1 + numOfItem * (i - 1)):(numOfItem * i),]$P),
nrow = numOfItem, ncol = 1, byrow = FALSE)
fxTheta[i, ] <- LordWingersky(probs)$probability
}
# reverse column sequence
fxTheta <- fxTheta[, c(ncol(fxTheta):1)]
# transform to data frame
fxTheta <- as.data.frame(fxTheta)
# transform data frame fxTheta
fxThetaT <- as.data.frame(t(fxTheta))
# reverse SS
fxThetaT$SS <- rev(convTable$roundedSS)
# true scale score
fxThetaTSS <- as.data.frame(apply(fxThetaT[c(1:numOfQuad)], 2, function(x) x * fxThetaT$SS))
fxThetaTSS$SS <- rev(convTable$roundedSS)
# merge data
fxThetaTSS <- rbind(fxThetaT, colSums(fxThetaTSS))
# CSSEM condtional on theta
cssemKolen <- matrix(NA,nrow = numOfQuad, ncol = 1)
for (i in 1:numOfQuad){
# cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:41),42] - fxThetaTSS[42, i])^2 * fxThetaTSS[c(1:41),i]))
cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:(numOfItem+1)),(numOfQuad+1)] - fxThetaTSS[(numOfItem+2), i])^2 * fxThetaTSS[c(1:(numOfItem+1)),i]))
}
# error variance: avarage CSSEM across theta distribution
errorVarKolen <- sum(cssemKolen^2 * quadPoints$weights)
#' @title IRT Reliability of Kolen's Method
#'
#' @description
#' A function to calculate IRT Reliability of Kolen's Method
#'
#' @param itemPara a text file with parameters of sequence b and a, a is on the 1.702 metric
#' @param convTable matrix or data frame contains raw score to scale score
#' @return a reliability number
#'
#' @author {Huan Liu, University of Iowa, \email{huan-liu-1@@uiowa.edu}}
#'
#' @export
KolenRelIRT <- function(itemPara, convTable){
itemPara <- itemPara_A
convTable <- convTable_A
if (ncol(itemPara) == 3){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a", "c")
}
if (ncol(itemPara) == 2){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara$c <- 0
}
if (ncol(itemPara) == 1){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b")
itemPara$a <- 1
itemPara$c <- 0
}
# number of quadrature
numOfQuad <- 41
# number of Items
numOfItem <- nrow(itemPara)
# weights and nodes
quadPoints <- NormalQuadraPoints(numOfQuad)
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(numOfItem), each = numOfQuad),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = numOfQuad*numOfItem)
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = c + (1 - c) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# reorder matrix by theta
itemParaRep <- itemParaRep[order(itemParaRep$theta),]
# create matrix to store f(x|theta)
fxTheta <- matrix(NA, nrow = numOfQuad, ncol = numOfItem + 1)
# for loop to calculate fxTheta
for (i in 1:numOfQuad){
probs <- matrix(c(itemParaRep[(1 + numOfItem * (i - 1)):(numOfItem * i),]$P),
nrow = numOfItem, ncol = 1, byrow = FALSE)
fxTheta[i, ] <- LordWingersky(probs)$probability
}
# reverse column sequence
fxTheta <- fxTheta[, c(ncol(fxTheta):1)]
# transform to data frame
fxTheta <- as.data.frame(fxTheta)
# transform data frame fxTheta
fxThetaT <- as.data.frame(t(fxTheta))
# reverse SS
fxThetaT$SS <- rev(convTable$roundedSS)
# true scale score
fxThetaTSS <- as.data.frame(apply(fxThetaT[c(1:numOfQuad)], 2, function(x) x * fxThetaT$SS))
fxThetaTSS$SS <- rev(convTable$roundedSS)
# merge data
fxThetaTSS <- rbind(fxThetaT, colSums(fxThetaTSS))
# CSSEM condtional on theta
cssemKolen <- matrix(NA,nrow = numOfQuad, ncol = 1)
for (i in 1:numOfQuad){
# cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:41),42] - fxThetaTSS[42, i])^2 * fxThetaTSS[c(1:41),i]))
cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:(numOfItem+1)),(numOfQuad+1)] - fxThetaTSS[(numOfItem+2), i])^2 * fxThetaTSS[c(1:(numOfItem+1)),i]))
}
# error variance: avarage CSSEM across theta distribution
errorVarKolen <- sum(cssemKolen^2 * quadPoints$weights)
# variance of scale score
fxPrXi <- as.data.frame(apply(fxTheta[c(1:numOfQuad)], 2, function(x) x * quadPoints$weights))
# mean of scale score
meanSS <- sum(rev(convTable$roundedSS) * colSums(fxPrXi))
# variance of scale score
SSVarKolen <- sum((rev(convTable$roundedSS) - meanSS)^2 * colSums(fxPrXi))
# reliability
kolenRelIRT <- 1 - errorVarKolen / SSVarKolen
return(kolenRelIRT)
}
# read conversion tables
convTable_A <- read.csv("TestData/ConversionTableFormX.csv")
convTable_A$roundedSS <- round(convTable_A$unroundedSS)
convTable_B <- read.csv("TestData/ConversionTableFormY.csv")
convTable_B$roundedSS <- round(convTable_B$unroundedSS)
KolenRelIRT_A <- KolenRelIRT(itemPara_A, convTable_A)
KolenRelIRT_A
KolenRelIRT_B <- KolenRelIRT(itemPara_B, convTable_B)
KolenRelIRT_B
convTable_A <- read.csv("TestData/conversion_table_Form A.csv")
convTable_A <- convTable_A[1:32, c("RawScore", "roundedSS")]
convTable_B <- read.csv("TestData/conversion_table_Form B.csv")
convTable_B <- convTable_B[1:32, c("RawScore", "roundedSS")]
KolenRelIRT_A_UIRT <- KolenRelIRT(itemPara_A_UIRT, convTable_A)
KolenRelIRT_A_UIRT
KolenRelIRT_B_UIRT <- KolenRelIRT(itemPara_B_UIRT, convTable_B)
KolenRelIRT_B_UIRT
# read conversion tables
convTable_A <- read.csv("TestData/conversion_table_Form A.csv")
convTable_A <- convTable_A[1:32, c("RawScore", "roundedSS")]
itemPara <- itemPara_A_UIRT#itemPara_A
convTable <- convTable_A
if (ncol(itemPara) == 3){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a", "c")
}
if (ncol(itemPara) == 2){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara$c <- 0
}
if (ncol(itemPara) == 1){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b")
itemPara$a <- 1
itemPara$c <- 0
}
# number of quadrature
numOfQuad <- 41
# number of Items
numOfItem <- nrow(itemPara)
# weights and nodes
quadPoints <- NormalQuadraPoints(numOfQuad)
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(numOfItem), each = numOfQuad),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = numOfQuad*numOfItem)
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = c + (1 - c) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# reorder matrix by theta
itemParaRep <- itemParaRep[order(itemParaRep$theta),]
# create matrix to store f(x|theta)
fxTheta <- matrix(NA, nrow = numOfQuad, ncol = numOfItem + 1)
# for loop to calculate fxTheta
for (i in 1:numOfQuad){
probs <- matrix(c(itemParaRep[(1 + numOfItem * (i - 1)):(numOfItem * i),]$P),
nrow = numOfItem, ncol = 1, byrow = FALSE)
fxTheta[i, ] <- LordWingersky(probs)$probability
}
# reverse column sequence
fxTheta <- fxTheta[, c(ncol(fxTheta):1)]
# transform to data frame
fxTheta <- as.data.frame(fxTheta)
# transform data frame fxTheta
fxThetaT <- as.data.frame(t(fxTheta))
# reverse SS
fxThetaT$SS <- rev(convTable$roundedSS)
# true scale score
fxThetaTSS <- as.data.frame(apply(fxThetaT[c(1:numOfQuad)], 2, function(x) x * fxThetaT$SS))
fxThetaTSS$SS <- rev(convTable$roundedSS)
# merge data
fxThetaTSS <- rbind(fxThetaT, colSums(fxThetaTSS))
# CSSEM condtional on theta
cssemKolen <- matrix(NA,nrow = numOfQuad, ncol = 1)
for (i in 1:numOfQuad){
# cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:41),42] - fxThetaTSS[42, i])^2 * fxThetaTSS[c(1:41),i]))
cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:(numOfItem+1)),(numOfQuad+1)] - fxThetaTSS[(numOfItem+2), i])^2 * fxThetaTSS[c(1:(numOfItem+1)),i]))
}
errorVarKolen <- sum(cssemKolen^2 * quadPoints$weights)
# variance of scale score
fxPrXi <- as.data.frame(apply(fxTheta[c(1:numOfQuad)], 2, function(x) x * quadPoints$weights))
#' @title IRT Reliability of Kolen's Method
#'
#' @description
#' A function to calculate IRT Reliability of Kolen's Method
#'
#' @param itemPara a text file with parameters of sequence b and a, a is on the 1.702 metric
#' @param convTable matrix or data frame contains raw score to scale score
#' @return a reliability number
#'
#' @author {Huan Liu, University of Iowa, \email{huan-liu-1@@uiowa.edu}}
#'
#' @export
KolenRelIRT <- function(itemPara, convTable){
# itemPara <- itemPara_A_UIRT#itemPara_A
# convTable <- convTable_A
if (ncol(itemPara) == 3){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a", "c")
}
if (ncol(itemPara) == 2){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara$c <- 0
}
if (ncol(itemPara) == 1){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b")
itemPara$a <- 1
itemPara$c <- 0
}
# number of quadrature
numOfQuad <- 41
# number of Items
numOfItem <- nrow(itemPara)
# weights and nodes
quadPoints <- NormalQuadraPoints(numOfQuad)
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(numOfItem), each = numOfQuad),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = numOfQuad*numOfItem)
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = c + (1 - c) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# reorder matrix by theta
itemParaRep <- itemParaRep[order(itemParaRep$theta),]
# create matrix to store f(x|theta)
fxTheta <- matrix(NA, nrow = numOfQuad, ncol = numOfItem + 1)
# for loop to calculate fxTheta
for (i in 1:numOfQuad){
probs <- matrix(c(itemParaRep[(1 + numOfItem * (i - 1)):(numOfItem * i),]$P),
nrow = numOfItem, ncol = 1, byrow = FALSE)
fxTheta[i, ] <- LordWingersky(probs)$probability
}
# reverse column sequence
fxTheta <- fxTheta[, c(ncol(fxTheta):1)]
# transform to data frame
fxTheta <- as.data.frame(fxTheta)
# transform data frame fxTheta
fxThetaT <- as.data.frame(t(fxTheta))
# reverse SS
fxThetaT$SS <- rev(convTable$roundedSS)
# true scale score
fxThetaTSS <- as.data.frame(apply(fxThetaT[c(1:numOfQuad)], 2, function(x) x * fxThetaT$SS))
fxThetaTSS$SS <- rev(convTable$roundedSS)
# merge data
fxThetaTSS <- rbind(fxThetaT, colSums(fxThetaTSS))
# CSSEM condtional on theta
cssemKolen <- matrix(NA,nrow = numOfQuad, ncol = 1)
for (i in 1:numOfQuad){
# cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:41),42] - fxThetaTSS[42, i])^2 * fxThetaTSS[c(1:41),i]))
cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:(numOfItem+1)),(numOfQuad+1)] - fxThetaTSS[(numOfItem+2), i])^2 * fxThetaTSS[c(1:(numOfItem+1)),i]))
}
# error variance: avarage CSSEM across theta distribution
errorVarKolen <- sum(cssemKolen^2 * quadPoints$weights)
# variance of scale score
fxPrXi <- as.data.frame(apply(fxTheta[c(1:(numOfItem+1))], 2, function(x) x * quadPoints$weights))
# mean of scale score
meanSS <- sum(rev(convTable$roundedSS) * colSums(fxPrXi))
# variance of scale score
SSVarKolen <- sum((rev(convTable$roundedSS) - meanSS)^2 * colSums(fxPrXi))
# reliability
kolenRelIRT <- 1 - errorVarKolen / SSVarKolen
return(kolenRelIRT)
}
# read conversion tables
convTable_A <- read.csv("TestData/ConversionTableFormX.csv")
convTable_A$roundedSS <- round(convTable_A$unroundedSS)
convTable_B <- read.csv("TestData/ConversionTableFormY.csv")
convTable_B$roundedSS <- round(convTable_B$unroundedSS)
KolenRelIRT_A <- KolenRelIRT(itemPara_A, convTable_A)
KolenRelIRT_A
KolenRelIRT_B <- KolenRelIRT(itemPara_B, convTable_B)
KolenRelIRT_B
# read conversion tables
convTable_A <- read.csv("TestData/conversion_table_Form A.csv")
convTable_A <- convTable_A[1:32, c("RawScore", "roundedSS")]
convTable_B <- read.csv("TestData/conversion_table_Form B.csv")
convTable_B <- convTable_B[1:32, c("RawScore", "roundedSS")]
KolenRelIRT_A_UIRT <- KolenRelIRT(itemPara_A_UIRT, convTable_A)
KolenRelIRT_A_UIRT
KolenRelIRT_B_UIRT <- KolenRelIRT(itemPara_B_UIRT, convTable_B)
KolenRelIRT_B_UIRT
# read item parameters
# form A
itemPara_BF_G <- read.table("TestData/SpanishLit_prm_A_BF.txt")[,c(7:11)]
KolenRelIRT(itemPara_BF_G, convTable_A)
itemPara_BF_G <- read.table("TestData/SpanishLit_prm_A_BF.txt")[,c(7:11)]
# form B
# itemPara_BF_G <- read.table("TestData/SpanishLit_prm_B_BF.txt")[,c(7:11)]
names(itemPara_BF_G) <- c("b", "ag","a1","a2", "a3") # a1 is primary
itemPara_BF_G$a <- c(itemPara_BF_G$a1[1:13], itemPara_BF_G$a2[14:25], itemPara_BF_G$a3[26:31])
itemPara_BF_G[,"b"] <- -itemPara_BF_G[,"b"]/(itemPara_BF_G[,"ag"] + itemPara_BF_G[,"a"]) #######?????????????????
itemPara_BF_G[,"a"] <- itemPara_BF_G[,"a"]/1.702
itemPara_BF_G$a1[1:13] <- itemPara_BF_G$a[1:13]
itemPara_BF_G$a2[14:25] <- itemPara_BF_G$a[14:25]
itemPara_BF_G$a3[26:31] <- itemPara_BF_G$a[26:31]
itemPara_BF_G$ag <- itemPara_BF_G$ag/1.702
itemPara_BF_G <- itemPara_BF_G[,c("b", "ag")]
names(itemPara_BF_G) <- c("b", "a")
KolenRelIRT(itemPara_BF_G, convTable_A)
# form A
# itemPara_BF_G <- read.table("TestData/SpanishLit_prm_A_BF.txt")[,c(7:11)]
# form B
itemPara_BF_G <- read.table("TestData/SpanishLit_prm_B_BF.txt")[,c(7:11)]
names(itemPara_BF_G) <- c("b", "ag","a1","a2", "a3") # a1 is primary
itemPara_BF_G$a <- c(itemPara_BF_G$a1[1:13], itemPara_BF_G$a2[14:25], itemPara_BF_G$a3[26:31])
itemPara_BF_G[,"b"] <- -itemPara_BF_G[,"b"]/(itemPara_BF_G[,"ag"] + itemPara_BF_G[,"a"]) #######?????????????????
itemPara_BF_G[,"a"] <- itemPara_BF_G[,"a"]/1.702
itemPara_BF_G$a1[1:13] <- itemPara_BF_G$a[1:13]
itemPara_BF_G$a2[14:25] <- itemPara_BF_G$a[14:25]
itemPara_BF_G$a3[26:31] <- itemPara_BF_G$a[26:31]
itemPara_BF_G$ag <- itemPara_BF_G$ag/1.702
itemPara_BF_G <- itemPara_BF_G[,c("b", "ag")]
names(itemPara_BF_G) <- c("b", "a")
TestRelIRT(itemPara_BF_G)
MarginalRelIRT(itemPara_BF_G, estType = "MLE")
MarginalRelIRT(itemPara_BF_G, estType = "EAP")
KolenRelIRT(itemPara_BF_G, convTable_B)
#' @title IRT Reliability of Kolen's Method
#'
#' @description
#' A function to calculate IRT Reliability of Kolen's Method
#'
#' @param itemPara a text file with parameters of sequence b and a, a is on the 1.702 metric
#' @param convTable matrix or data frame contains raw score to scale score
#' @return a reliability number
#'
#' @author {Huan Liu, University of Iowa, \email{huan-liu-1@@uiowa.edu}}
#'
#' @export
KolenRelIRT <- function(itemPara, convTable){
# itemPara <- itemPara_A_UIRT#itemPara_A
# convTable <- convTable_A
if (ncol(itemPara) == 3){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a", "c")
}
if (ncol(itemPara) == 2){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara$c <- 0
}
if (ncol(itemPara) == 1){
#  item parameters should be on the 1.702 metric
names(itemPara) <- c("b")
itemPara$a <- 1
itemPara$c <- 0
}
# number of quadrature
numOfQuad <- 41
# number of Items
numOfItem <- nrow(itemPara)
# weights and nodes
quadPoints <- NormalQuadraPoints(numOfQuad)
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(numOfItem), each = numOfQuad),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = numOfQuad*numOfItem)
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = c + (1 - c) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# reorder matrix by theta
itemParaRep <- itemParaRep[order(itemParaRep$theta),]
# create matrix to store f(x|theta)
fxTheta <- matrix(NA, nrow = numOfQuad, ncol = numOfItem + 1)
# for loop to calculate fxTheta
for (i in 1:numOfQuad){
probs <- matrix(c(itemParaRep[(1 + numOfItem * (i - 1)):(numOfItem * i),]$P),
nrow = numOfItem, ncol = 1, byrow = FALSE)
fxTheta[i, ] <- LordWingersky(probs)$probability
}
# reverse column sequence
fxTheta <- fxTheta[, c(ncol(fxTheta):1)]
# transform to data frame
fxTheta <- as.data.frame(fxTheta)
# transform data frame fxTheta
fxThetaT <- as.data.frame(t(fxTheta))
# reverse SS
fxThetaT$SS <- rev(convTable$roundedSS)
# true scale score
fxThetaTSS <- as.data.frame(apply(fxThetaT[c(1:numOfQuad)], 2, function(x) x * fxThetaT$SS))
fxThetaTSS$SS <- rev(convTable$roundedSS)
# merge data
fxThetaTSS <- rbind(fxThetaT, colSums(fxThetaTSS))
# CSSEM condtional on theta
cssemKolen <- matrix(NA,nrow = numOfQuad, ncol = 1)
for (i in 1:numOfQuad){
# cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:41),42] - fxThetaTSS[42, i])^2 * fxThetaTSS[c(1:41),i]))
cssemKolen[i, 1] <- sqrt(sum((fxThetaTSS[c(1:(numOfItem+1)),(numOfQuad+1)] - fxThetaTSS[(numOfItem+2), i])^2 * fxThetaTSS[c(1:(numOfItem+1)),i]))
}
# error variance: avarage CSSEM across theta distribution
errorVarKolen <- sum(cssemKolen^2 * quadPoints$weights)
# variance of scale score
fxPrXi <- as.data.frame(apply(fxTheta[c(1:(numOfItem+1))], 2, function(x) x * quadPoints$weights))
# mean of scale score
meanSS <- sum(rev(convTable$roundedSS) * colSums(fxPrXi))
# variance of scale score
SSVarKolen <- sum((rev(convTable$roundedSS) - meanSS)^2 * colSums(fxPrXi))
# reliability
kolenRelIRT <- 1 - errorVarKolen / SSVarKolen
return(kolenRelIRT)
}
# read conversion tables
convTable_A <- read.csv("TestData/ConversionTableFormX.csv")
convTable_A$roundedSS <- round(convTable_A$unroundedSS)
convTable_B <- read.csv("TestData/ConversionTableFormY.csv")
convTable_B$roundedSS <- round(convTable_B$unroundedSS)
KolenRelIRT_A <- KolenRelIRT(itemPara_A, convTable_A)
KolenRelIRT_A
KolenRelIRT_B <- KolenRelIRT(itemPara_B, convTable_B)
KolenRelIRT_B
# form B
itemPara_BF_G <- read.table("TestData/SpanishLit_prm_B_BF.txt")[,c(7:11)]
names(itemPara_BF_G) <- c("b", "ag","a1","a2", "a3") # a1 is primary
itemPara_BF_G$a <- c(itemPara_BF_G$a1[1:13], itemPara_BF_G$a2[14:25], itemPara_BF_G$a3[26:31])
itemPara_BF_G[,"b"] <- -itemPara_BF_G[,"b"]/(itemPara_BF_G[,"ag"] + itemPara_BF_G[,"a"]) #######?????????????????
itemPara_BF_G[,"a"] <- itemPara_BF_G[,"a"]/1.702
itemPara_BF_G$a1[1:13] <- itemPara_BF_G$a[1:13]
itemPara_BF_G$a2[14:25] <- itemPara_BF_G$a[14:25]
itemPara_BF_G$a3[26:31] <- itemPara_BF_G$a[26:31]
itemPara_BF_G$ag <- itemPara_BF_G$ag/1.702
itemPara_BF_G <- itemPara_BF_G[,c("b", "ag")]
names(itemPara_BF_G) <- c("b", "a")
TestRelIRT(itemPara_BF_G)
MarginalRelIRT(itemPara_BF_G, estType = "MLE")
MarginalRelIRT(itemPara_BF_G, estType = "EAP")
KolenRelIRT(itemPara_BF_G, convTable_B)
# read conversion tables
convTable_A <- read.csv("TestData/conversion_table_Form A.csv")
convTable_A <- convTable_A[1:32, c("RawScore", "roundedSS")]
convTable_B <- read.csv("TestData/conversion_table_Form B.csv")
convTable_B <- convTable_B[1:32, c("RawScore", "roundedSS")]
KolenRelIRT(itemPara_BF_G, convTable_B)
