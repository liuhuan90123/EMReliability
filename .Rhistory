n <- 41
# set nodes
nodes <- seq(-5, 5, length.out = n)
weightsUnwtd <- apply(nodes, 1, FUN = function(x) dnorm(x))
# set nodes
nodes <- as.matrix(seq(-5, 5, length.out = n))
View(nodes)
weightsUnwtd <- apply(nodes, 1, FUN = function(x) dnorm(x))
weightsWtd <- weightsUnwtd / sum(weightsUnwtd)
return(list(nodes, weightsWtd))
ist(nodes, weightsWtd)
list(nodes, weightsWtd)
# set nodes
nodes <- as.matrix(seq(-5, 5, length.out = n))
weightsUnwtd <- sapply(nodes, 1, FUN = function(x) dnorm(x))
nodes <- as.matrix(seq(-5, 5, length.out = n))
weightsUnwtd <- sapply(nodes, FUN = function(x) dnorm(x))
# set nodes
nodes <- seq(-5, 5, length.out = n)
weightsUnwtd <- sapply(nodes, FUN = function(x) dnorm(x))
weightsWtd <- weightsUnwtd / sum(weightsUnwtd)
return(list(nodes, weightsWtd))
list(nodes, weightsWtd)
NormalQuadraPoints <- function(n){
# set nodes ranging from -5 to 5
nodes <- seq(-5, 5, length.out = n)
# unnormalized weights
weightsUnwtd <- sapply(nodes, FUN = function(x) dnorm(x))
# normalized weightes
weightsWtd <- weightsUnwtd / sum(weightsUnwtd)
# return nodes and normalized weights
return(list(nodes, weightsWtd))
}
NormalQuadraPoints(41)
NormalQuadraPoints <- function(n){
# set nodes ranging from -5 to 5
nodes <- seq(-5, 5, length.out = n)
# unnormalized weights
weightsUnwtd <- sapply(nodes, FUN = function(x) dnorm(x))
# normalized weightes
weightsWtd <- weightsUnwtd / sum(weightsUnwtd)
# return nodes and normalized weights
return(list(nodes, weightsWtd))
}
NormalQuadraPoints(41)
### normal density function
options(scipen = 999)
# function
normalDensity <- function(x, mean, sd){
1 / sqrt(2 * pi * sd^2) * exp(-0.5 * ((x-mean)/sd)^2)
}
# Kole&Lee's examples
normalWtKolen <- read.table("TestData/NW_Kolen.txt")
names(normalWtKolen) <- c("nodes", "weightsKolen")
normalWtLee <- read.table("TestData/NW_Lee.txt")
names(normalWtLee) <- c("nodes", "weightsLee")
# merge data
normalWtCom <- merge(normalWtKolen, normalWtLee, by = "nodes")
# compare K&L
normalWtCom$diffKL <- normalWtCom$weightsKolen - normalWtCom$weightsLee
sum(normalWtCom$diffKL)
# calculate Huan
normalWtCom$weightsHuanUnwtd <- apply(normalWtCom["nodes"], 1, FUN=function(x) dnorm(x))
normalWtCom$weightsHuanWtd <- normalWtCom$weightsHuanUnwtd/sum(normalWtCom$weightsHuanUnwtd)
sum(normalWtCom$weightsHuanWtd)
# compare Huan to K&L
normalWtCom$diffKH <- normalWtCom$weightsKolen - normalWtCom$weightsHuanWtd
sum(normalWtCom$diffKH)
normalWtCom$diffLH <- normalWtCom$weightsLee - normalWtCom$weightsHuanWtd
sum(normalWtCom$diffLH)
gauss.quad.prob(41, dist = "normal", mu = 0, sigma = 1)
str(quadPoints)
quadratureHuan <- NormalQuadraPoints(41)
str(quadratureHuan)
NormalQuadraPoints <- function(n){
# set nodes ranging from -5 to 5
nodes <- seq(-5, 5, length.out = n)
# unnormalized weights
weightsUnwtd <- sapply(nodes, FUN = function(x) dnorm(x))
# normalized weightes
weightsWtd <- weightsUnwtd / sum(weightsUnwtd)
# return nodes and normalized weights
return(list(nodes = "nodes", weightsWtd = "weighted"))
}
quadratureHuan <- NormalQuadraPoints(41)
str(quadratureHuan)
NormalQuadraPoints <- function(n){
# set nodes ranging from -5 to 5
nodes <- seq(-5, 5, length.out = n)
# unnormalized weights
weightsUnwtd <- sapply(nodes, FUN = function(x) dnorm(x))
# normalized weightes
weightsWtd <- weightsUnwtd / sum(weightsUnwtd)
# return nodes and normalized weights
return(list("nodes" = nodes, "weightes" = weightsWtd))
}
quadratureHuan <- NormalQuadraPoints(41)
str(quadratureHuan)
NormalQuadraPoints <- function(n){
# set nodes ranging from -5 to 5
nodes <- seq(-5, 5, length.out = n)
# unnormalized weights
weightsUnwtd <- sapply(nodes, FUN = function(x) dnorm(x))
# normalized weightes
weightsWtd <- weightsUnwtd / sum(weightsUnwtd)
# return nodes and normalized weights
return(list("nodes" = nodes, "weights" = weightsWtd))
}
quadratureHuan <- NormalQuadraPoints(41)
str(quadratureHuan)
itemPara <- read.table("TestData/ItemParaFormX.txt")
MarginalRelMLE(itemPara)
library(devtools)
install_github("liuhuan90123/EMReliability")
source("R/CSEMLord.R")
source("R/PolynomialMethod.R")
### CSSEM Polynomial Method
source("R/CSEMLord.R")
source("R/PolynomialMethod.R")
# Note: 1. cssemDat should include rawScore, roundedSS, and Lordcsem
#       2. conversion table should include raw score and rounded scale score
# read conversion table from cvs file
convTable <- read.csv("TestData/ConversionTableFormX.csv")
convTable$roundedSS <- round(convTable$unroundedSS)
convTableSub <- convTable[,c("rawScore", "roundedSS")]
# number of item
numOfItem <- 40
# highest degree of polynomial regression requested
K <- 15
CSSEMPolynomial <- function(numOfItem, convTable, K){
csemLordDat <- CSEMLord(numOfItem)
cssemDat <- merge(csemLordDat, convTableSub, by = "rawScore")
PolynomialMethod(cssemDat, K)
}
CSSEMPolynomial(numOfItem, convTableSub, K)
### CSSEM Polynomial Method
source("R/CSEMLord.R")
source("R/PolynomialMethod.R")
# Note: 1. cssemDat should include rawScore, roundedSS, and Lordcsem
#       2. conversion table should include raw score and rounded scale score
# read conversion table from cvs file
convTable <- read.csv("TestData/ConversionTableFormX.csv")
convTable$roundedSS <- round(convTable$unroundedSS)
convTableSub <- convTable[,c("rawScore", "roundedSS")]
# number of item
numOfItem <- 40
# highest degree of polynomial regression requested
K <- 15
CSSEMPolynomial <- function(numOfItem, convTable, K){
csemLordDat <- CSEMLord(numOfItem)
cssemDat <- merge(csemLordDat, convTableSub, by = "rawScore")
PolynomialMethod(cssemDat, K)
}
CSSEMPolynomial(numOfItem, convTableSub, K)
source("R/CSEMLord.R")
source("R/PolynomialMethod.R")
# Note: 1. cssemDat should include rawScore, roundedSS, and Lordcsem
#       2. conversion table should include raw score and rounded scale score
# read conversion table from cvs file
convTable <- read.csv("TestData/ConversionTableFormX.csv")
convTable$roundedSS <- round(convTable$unroundedSS)
convTableSub <- convTable[,c("rawScore", "roundedSS")]
# number of item
numOfItem <- 40
# highest degree of polynomial regression requested
K <- 15
CSSEMPolynomial <- function(numOfItem, convTable, K){
csemLordDat <- CSEMLord(numOfItem)
cssemDat <- merge(csemLordDat, convTableSub, by = "rawScore")
PolynomialMethod(cssemDat, K)
}
CSSEMPolynomial(numOfItem, convTableSub, K)
str(CSSEMPolynomial(numOfItem, convTableSub, K))
CSSEMPolynomial(numOfItem, convTableSub, K)
#### Plot --------------------------------------
library(ggplot2)
### aggregate many to one ------------
cssemDatWide <- CSSEMPolynomial(40, convTableSub, K)
cssemDat <- cssemDatWide # test
k <- 13 # test, accepted maximum + 1
cssemDat <- cssemDat[,c(3,5:(5+k-2))]
cssemDatAggre <- as.data.frame(apply(cssemDat[,c(-1)], 2, function(x) aggregate(x, by=list(Category=cssemDat$roundedSS), FUN=mean)))
cssemDatAggre <- cssemDatAggre[,c(1, seq(2, 24, 2))]
### range and confidence interval  with k from 1 to maximum accepted ----------
cssemDatAggre$max <- apply(cssemDatAggre[,c(-1)], 1, max)
cssemDatAggre$min <- apply(cssemDatAggre[,c(-1)], 1, min)
cssemDatAggre$mean <- apply(cssemDatAggre[,c(-1)], 1, mean)
cssemDatAggre$median <- apply(cssemDatAggre[,c(-1)], 1, median)
cssemDatAggre$sd <- apply(cssemDatAggre[,c(-1)], 1, sd)
# 95% confidence interval
cssemDatAggre_1 <- within(cssemDatAggre, {
lower = mean - 1.96 * sd
upper = mean + 1.96 * sd
})
### plot confidence interval
# k = 1 to maximum accepted
ggplot(cssemDatAggre_1, aes(x = cssemPolyk1.Category, y = mean)) +
geom_line(colour ="blue") +
geom_point(colour="blue") +
geom_ribbon(aes(ymin = lower, ymax = upper), fill= "blue", alpha = 0.2) +
scale_x_continuous(name = "Rounded Scale Score", breaks  = seq(100, 130, 5)) +
scale_y_continuous(name = "CSSEM Polynomial Method") +
theme_bw()
### range and confidence interval  with k from 3 to maximum accepted ---33333333333-------
cssemDatAggre$max <- apply(cssemDatAggre[,c(-1:-3)], 1, max)
cssemDatAggre$min <- apply(cssemDatAggre[,c(-1:-3)], 1, min)
cssemDatAggre$mean <- apply(cssemDatAggre[,c(-1:-3)], 1, mean)
cssemDatAggre$median <- apply(cssemDatAggre[,c(-1:-3)], 1, median)
cssemDatAggre$sd <- apply(cssemDatAggre[,c(-1:-3)], 1, sd)
# 95% confidence interval
cssemDatAggre <- within(cssemDatAggre, {
lower = mean - 1.96 * sd
upper = mean + 1.96 * sd
})
### plot confidence interval
# k = 1 to maximum accepted
ggplot(cssemDatAggre, aes(x = cssemPolyk1.Category, y = mean)) +
geom_line(colour ="blue") +
geom_point(colour="blue") +
geom_ribbon(aes(ymin = lower, ymax = upper), fill= "blue", alpha = 0.2) +
scale_x_continuous(name = "Rounded Scale Score", breaks  = seq(100, 130, 5)) +
scale_y_continuous(name = "CSSEM Polynomial Method") +
theme_bw()
# hist(as.numeric((cssemDatAggre[11,c(2:13)])))
### questions ---------------------------------------------
## maximum and minimum of k values
## R square matrix : check r squared change of k from 1 to 40
## unique scale scores
## range and confidence interval for each rounded scale score, print confidence interval
### plot ---------------------------------------------------
k <- 13 # The maximum accepted K
cssemDatLong <- reshape(cssemDatAggre,
direction = "long",
varying = list(names(cssemDatAggre)[2:k]),
v.names = "cssempoly",
idvar = c("cssemPolyk1.Category"),
timevar = "Kvalue",
times = 1:(k-1))
library(ggplot2)
ggplot(cssemDatLong, aes(x = cssemPolyk1.Category, y = cssempoly, color = factor(Kvalue))) +
geom_point() +
scale_x_continuous(name = "Rounded Scale Score", breaks  = seq(100, 130, 5)) +
scale_y_continuous(name = "CSSEM Polynomial Method") +
geom_line() +
theme_bw() +
labs(colour="K value")
CSSEMPolynomial(40, convTableSub, K)
cssemDatWide <- CSSEMPolynomial(40, convTableSub, K)
cssemDat <- cssemDatWide # test
k <- 13 # test, accepted maximum + 1
cssemDat <- cssemDat[,c(3,5:(5+k-2))]
cssemDatAggre <- as.data.frame(apply(cssemDat[,c(-1)], 2, function(x) aggregate(x, by=list(Category=cssemDat$roundedSS), FUN=mean)))
cssemDatAggre <- cssemDatAggre[,c(1, seq(2, 24, 2))]
CSSEMPolynomial(40, convTableSub, K)
cssemDatWide <- CSSEMPolynomial(40, convTableSub, K)$"CSSEM Polynomial Method"
cssemDat <- cssemDatWide # test
k <- 13 # test, accepted maximum + 1
cssemDat <- cssemDat[,c(3,5:(5+k-2))]
cssemDatAggre <- as.data.frame(apply(cssemDat[,c(-1)], 2, function(x) aggregate(x, by=list(Category=cssemDat$roundedSS), FUN=mean)))
cssemDatAggre <- cssemDatAggre[,c(1, seq(2, 24, 2))]
### range and confidence interval  with k from 1 to maximum accepted ----------
cssemDatAggre$max <- apply(cssemDatAggre[,c(-1)], 1, max)
cssemDatAggre$min <- apply(cssemDatAggre[,c(-1)], 1, min)
cssemDatAggre$mean <- apply(cssemDatAggre[,c(-1)], 1, mean)
cssemDatAggre$median <- apply(cssemDatAggre[,c(-1)], 1, median)
cssemDatAggre$sd <- apply(cssemDatAggre[,c(-1)], 1, sd)
# 95% confidence interval
cssemDatAggre_1 <- within(cssemDatAggre, {
lower = mean - 1.96 * sd
upper = mean + 1.96 * sd
})
### plot confidence interval
# k = 1 to maximum accepted
ggplot(cssemDatAggre_1, aes(x = cssemPolyk1.Category, y = mean)) +
geom_line(colour ="blue") +
geom_point(colour="blue") +
geom_ribbon(aes(ymin = lower, ymax = upper), fill= "blue", alpha = 0.2) +
scale_x_continuous(name = "Rounded Scale Score", breaks  = seq(100, 130, 5)) +
scale_y_continuous(name = "CSSEM Polynomial Method") +
theme_bw()
### range and confidence interval  with k from 3 to maximum accepted ---33333333333-------
cssemDatAggre$max <- apply(cssemDatAggre[,c(-1:-3)], 1, max)
cssemDatAggre$min <- apply(cssemDatAggre[,c(-1:-3)], 1, min)
cssemDatAggre$mean <- apply(cssemDatAggre[,c(-1:-3)], 1, mean)
cssemDatAggre$median <- apply(cssemDatAggre[,c(-1:-3)], 1, median)
cssemDatAggre$sd <- apply(cssemDatAggre[,c(-1:-3)], 1, sd)
# 95% confidence interval
cssemDatAggre <- within(cssemDatAggre, {
lower = mean - 1.96 * sd
upper = mean + 1.96 * sd
})
### plot confidence interval
# k = 1 to maximum accepted
ggplot(cssemDatAggre, aes(x = cssemPolyk1.Category, y = mean)) +
geom_line(colour ="blue") +
geom_point(colour="blue") +
geom_ribbon(aes(ymin = lower, ymax = upper), fill= "blue", alpha = 0.2) +
scale_x_continuous(name = "Rounded Scale Score", breaks  = seq(100, 130, 5)) +
scale_y_continuous(name = "CSSEM Polynomial Method") +
theme_bw()
# hist(as.numeric((cssemDatAggre[11,c(2:13)])))
### questions ---------------------------------------------
## maximum and minimum of k values
## R square matrix : check r squared change of k from 1 to 40
## unique scale scores
## range and confidence interval for each rounded scale score, print confidence interval
### plot ---------------------------------------------------
k <- 13 # The maximum accepted K
cssemDatLong <- reshape(cssemDatAggre,
direction = "long",
varying = list(names(cssemDatAggre)[2:k]),
v.names = "cssempoly",
idvar = c("cssemPolyk1.Category"),
timevar = "Kvalue",
times = 1:(k-1))
library(ggplot2)
ggplot(cssemDatLong, aes(x = cssemPolyk1.Category, y = cssempoly, color = factor(Kvalue))) +
geom_point() +
scale_x_continuous(name = "Rounded Scale Score", breaks  = seq(100, 130, 5)) +
scale_y_continuous(name = "CSSEM Polynomial Method") +
geom_line() +
theme_bw() +
labs(colour="K value")
### plot all ks ---------------------------------------------------
k <- 13 # The maximum accepted K
cssemDatLong <- reshape(cssemDatAggre,
direction = "long",
varying = list(names(cssemDatAggre)[2:k]),
v.names = "cssempoly",
idvar = c("cssemPolyk1.Category"),
timevar = "Kvalue",
times = 1:(k-1))
library(ggplot2)
ggplot(cssemDatLong, aes(x = cssemPolyk1.Category, y = cssempoly, color = factor(Kvalue))) +
geom_point() +
scale_x_continuous(name = "Rounded Scale Score", breaks  = seq(100, 130, 5)) +
scale_y_continuous(name = "CSSEM Polynomial Method") +
geom_line() +
theme_bw() +
labs(colour="K value")
### CSSEM IRT MLE Polynomial Method
# read item parameter
itemPara <- read.table("TestData/ItemParaFormX.txt")
# read conversion table from cvs file
convTable <- read.csv("TestData/ConversionTableFormX.csv")
convTable$roundedSS <- round(convTable$unroundedSS)
convTableSub <- convTable[,c("thetaScore", "roundedSS")]
source("R/PolynomialMethod.R")
library(statmod)
CSSEMMLEPoly <- function(itemPara, convTable, K){
# transform item parameters to the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara[,"a"] <- itemPara[,"a"]/1.702
# weights and nodes
quadPoints <- NormalQuadraPoints(41)
# replace nodes with theta score in coversion table
quadPoints$nodes <- convTable$thetaScore
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(nrow(itemPara)), each = 41),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = 41*nrow(itemPara))
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = 0 + (1 - 0) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# sum information by theta
itemParaInfo <- aggregate(itemParaRep$info, by=list(Category=itemParaRep$theta), FUN=sum)
names(itemParaInfo) <- c("thetaScore", "infoSum")
# merge data
itemParaInfo <- merge(itemParaInfo, convTable, by = "thetaScore")
# transform inforamtion to csem
itemParaInfo$csemMLE <- sqrt(1/itemParaInfo$infoSum)
# change name to fit Polynomial Method function
names(itemParaInfo) <- c("rawScore", "infoSum", "roundedSS", "csemLord")
PolynomialMethod(itemParaInfo, K)
}
K <- 20
CSSEMMLEPoly(itemPara, convTableSub, K) ### variable name should be changed
names(CSSEMMLEPoly(itemPara, convTableSub, K))
names(CSSEMMLEPoly(itemPara, convTableSub, K)$`CSSEM Polynomial Method`)
### CSSEM IRT MLE Polynomial Method
# read item parameter
itemPara <- read.table("TestData/ItemParaFormX.txt")
# read conversion table from cvs file
convTable <- read.csv("TestData/ConversionTableFormX.csv")
convTable$roundedSS <- round(convTable$unroundedSS)
convTableSub <- convTable[,c("thetaScore", "roundedSS")]
source("R/PolynomialMethod.R")
library(statmod)
CSSEMMLEPoly <- function(itemPara, convTable, K){
# transform item parameters to the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara[,"a"] <- itemPara[,"a"]/1.702
# weights and nodes
quadPoints <- NormalQuadraPoints(41)
# replace nodes with theta score in coversion table
quadPoints$nodes <- convTable$thetaScore
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(nrow(itemPara)), each = 41),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = 41*nrow(itemPara))
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = 0 + (1 - 0) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# sum information by theta
itemParaInfo <- aggregate(itemParaRep$info, by=list(Category=itemParaRep$theta), FUN=sum)
names(itemParaInfo) <- c("thetaScore", "infoSum")
# merge data
itemParaInfo <- merge(itemParaInfo, convTable, by = "thetaScore")
# transform inforamtion to csem
itemParaInfo$csemMLE <- sqrt(1/itemParaInfo$infoSum)
# change name to fit Polynomial Method function
names(itemParaInfo) <- c("rawScore", "infoSum", "roundedSS", "csemLord")
PolynomialMethod(itemParaInfo, K)
}
K <- 20
CSSEMMLEPoly(itemPara, convTableSub, K) ### variable name should be changed
names(CSSEMMLEPoly(itemPara, convTableSub, K)$`CSSEM Polynomial Method`)
### select column without negative values?
### reliability
# rounded scale score reliability; k = 4
cssemMLEPolyDat <- CSSEMMLEPoly(itemPara, convTableSub, K)$`CSSEM Polynomial Method`
cssemMLEPolyDat$rawScore <- c(0:40)
### raw score frequency
# read raw data
rawData <- read.table("TestData/RawDataFormX.txt", header = F, sep = " ")
rawFreq <- as.data.frame(table(rowSums(rawData)))
names(rawFreq) <- c("rawScore", "freq")
cssemMLEPolyDat <- merge(cssemMLEPolyDat, rawFreq, by = "rawScore")
# weight
cssemMLEPolyDat$wt <- cssemMLEPolyDat$freq / sum(cssemMLEPolyDat$freq)
library(SDMTools)
# select k = 4
MLE <- 1 - sum(cssemMLEPolyDat$cssemPolyk4^2 * cssemMLEPolyDat$wt)/wt.var(cssemMLEPolyDat$roundedSS, cssemMLEPolyDat$wt)
MLE
View(cssemMLEPolyDat)
### CSSEM IRT MLE Polynomial Method
# read item parameter
itemPara <- read.table("TestData/ItemParaFormX.txt")
# read conversion table from cvs file
convTable <- read.csv("TestData/ConversionTableFormX.csv")
convTable$roundedSS <- round(convTable$unroundedSS)
convTableSub <- convTable[,c("thetaScore", "roundedSS")]
source("R/PolynomialMethod.R")
library(statmod)
CSSEMMLEPoly <- function(itemPara, convTable, K){
# transform item parameters to the 1.702 metric
names(itemPara) <- c("b", "a")
itemPara[,"a"] <- itemPara[,"a"]/1.702
# weights and nodes
quadPoints <- NormalQuadraPoints(41)
# replace nodes with theta score in coversion table
quadPoints$nodes <- convTable$thetaScore
# replicate item parameter and theta
itemParaRep <-itemPara[rep(seq_len(nrow(itemPara)), each = 41),]
itemParaRep$theta <- rep(quadPoints$nodes, each = 1, length.out = 41*nrow(itemPara))
# calculate information by theta
itemParaRep <- within(itemParaRep, {
P = 0 + (1 - 0) / (1 + exp(-1.702 * a * (theta - b)))
Q = 1 - P
PQ = P * Q
info = 1.702**2 * a**2 * P * Q
})
# sum information by theta
itemParaInfo <- aggregate(itemParaRep$info, by=list(Category=itemParaRep$theta), FUN=sum)
names(itemParaInfo) <- c("thetaScore", "infoSum")
# merge data
itemParaInfo <- merge(itemParaInfo, convTable, by = "thetaScore")
# transform inforamtion to csem
itemParaInfo$csemMLE <- sqrt(1/itemParaInfo$infoSum)
# change name to fit Polynomial Method function
names(itemParaInfo) <- c("rawScore", "infoSum", "roundedSS", "csemLord")
PolynomialMethod(itemParaInfo, K)
}
K <- 20
CSSEMMLEPoly(itemPara, convTableSub, K) ### variable name should be changed
# names(CSSEMMLEPoly(itemPara, convTableSub, K)$`CSSEM Polynomial Method`)
### select column without negative values?
### reliability
# rounded scale score reliability; k = 4
cssemMLEPolyDat <- CSSEMMLEPoly(itemPara, convTableSub, K)$`CSSEM Polynomial Method`
cssemMLEPolyDat$rawScore <- c(0:40)
### raw score frequency
# read raw data
rawData <- read.table("TestData/RawDataFormX.txt", header = F, sep = " ")
rawFreq <- as.data.frame(table(rowSums(rawData)))
names(rawFreq) <- c("rawScore", "freq")
cssemMLEPolyDat <- merge(cssemMLEPolyDat, rawFreq, by = "rawScore")
# weight
cssemMLEPolyDat$wt <- cssemMLEPolyDat$freq / sum(cssemMLEPolyDat$freq)
library(SDMTools)
# select k = 4
MLE <- 1 - sum(cssemMLEPolyDat$cssemPolyk4^2 * cssemMLEPolyDat$wt)/wt.var(cssemMLEPolyDat$roundedSS, cssemMLEPolyDat$wt)
MLE
source("R/TestRelIRT.R") # itemPara
# read item parameters from txt file
itemPara <- read.table("TestData/ItemParaFormX.txt")
TestRelIRT_A <- TestRelIRT(itemPara)
itemPara <- read.table("TestData/ItemParaFormY.txt")
TestRelIRT_B <- TestRelIRT(itemPara)
library(classify)
source("R/TestRelIRT.R") # itemPara
# read item parameters from txt file
itemPara <- read.table("TestData/ItemParaFormX.txt")
TestRelIRT_A <- TestRelIRT(itemPara)
itemPara <- read.table("TestData/ItemParaFormY.txt")
TestRelIRT_B <- TestRelIRT(itemPara)
